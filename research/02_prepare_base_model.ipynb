{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f31195e-cb6a-41a7-83dc-9e5ea9c09498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8302bbe-f860-40e8-99f9-0f6f93be0c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab/Workspace/e2e-mlflow-dvc\n"
     ]
    }
   ],
   "source": [
    "%cd /home/lab/Workspace/e2e-mlflow-dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9c6264c-97b0-413a-b763-f7b7d91ef54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    params_image_size: list\n",
    "    params_learning_rate: float\n",
    "    params_include_top: bool\n",
    "    params_weights: str\n",
    "    params_classes: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba47753-fd0c-4914-8dc9-fd2ac77520a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af61c6cf-1dd2-43e6-b6ac-3e126c7609a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        # Create artifacts root directory\n",
    "        create_directories([self.config[\"artifacts_root\"]])  # Access dictionary key correctly\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        # Access prepare_base_model section of config\n",
    "        config = self.config[\"prepare_base_model\"]  \n",
    "\n",
    "        # Create the directory for the base model\n",
    "        create_directories([config[\"root_dir\"]])\n",
    "\n",
    "        # Build PrepareBaseModelConfig object\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config[\"root_dir\"]),\n",
    "            base_model_path=Path(config[\"base_model_path\"]),\n",
    "            updated_base_model_path=Path(config[\"updated_base_model_path\"]),\n",
    "            params_image_size=self.params[\"IMAGE_SIZE\"],\n",
    "            params_learning_rate=self.params[\"LEARNING_RATE\"],\n",
    "            params_include_top=self.params[\"INCLUDE_TOP\"],\n",
    "            params_weights=self.params[\"WEIGHTS\"],\n",
    "            params_classes=self.params[\"CLASSES\"]\n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc038308-77b3-4a63-aede-28a62c8a6cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 14:51:51.327595: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-23 14:51:51.430518: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-23 14:51:52.597891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f0cb99c-ca9d-4286-bfa7-48487309e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "    def __init__(self, config: PrepareBaseModelConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        try:\n",
    "            # Validate input shape\n",
    "            input_shape = tuple(self.config.params_image_size)\n",
    "            \n",
    "            # Print configuration for debugging\n",
    "            print(\"Model Configuration:\")\n",
    "            print(f\"Input Shape: {input_shape}\")\n",
    "            print(f\"Weights: {self.config.params_weights}\")\n",
    "            print(f\"Include Top: {self.config.params_include_top}\")\n",
    "            print(f\"Classes: {self.config.params_classes}\")\n",
    "\n",
    "            # Adjust VGG16 initialization\n",
    "            self.model = tf.keras.applications.VGG16(\n",
    "                input_shape=input_shape,\n",
    "                weights=self.config.params_weights,\n",
    "                include_top=self.config.params_include_top,\n",
    "                classes=self.config.params_classes if self.config.params_include_top else None\n",
    "            )\n",
    "            \n",
    "            self.save_model(path=self.config.base_model_path, model=self.model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_base_model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate):\n",
    "        if freeze_all:\n",
    "            for layer in model.layers:\n",
    "                layer.trainable = False\n",
    "        elif (freeze_till is not None) and (freeze_till > 0):\n",
    "            for layer in model.layers[:-freeze_till]:\n",
    "                layer.trainable = False\n",
    "        \n",
    "        flatten_in = tf.keras.layers.Flatten()(model.output)\n",
    "        prediction = tf.keras.layers.Dense(\n",
    "            units=classes,\n",
    "            activation=\"softmax\"\n",
    "        )(flatten_in)\n",
    "        \n",
    "        full_model = tf.keras.models.Model(\n",
    "            inputs=model.input,\n",
    "            outputs=prediction\n",
    "        )\n",
    "        \n",
    "        full_model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        full_model.summary()\n",
    "        return full_model\n",
    "    \n",
    "    def update_base_model(self):\n",
    "        self.full_model = self._prepare_full_model(\n",
    "            model=self.model,\n",
    "            classes=self.config.params_classes,\n",
    "            freeze_all=True,\n",
    "            freeze_till=None,\n",
    "            learning_rate=self.config.params_learning_rate\n",
    "        )\n",
    "        self.save_model(path=self.config.updated_base_model_path, model=self.full_model)\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa08a43c-2a9a-4ebc-b99a-1b00fda6fdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-23 14:51:54,298: INFO: common: YAML file loaded successfully: config/config.yaml]\n",
      "[2025-01-23 14:51:54,304: INFO: common: YAML file loaded successfully: params.yaml]\n",
      "[2025-01-23 14:51:54,306: INFO: common: Created directory at: artifacts]\n",
      "[2025-01-23 14:51:54,308: INFO: common: Created directory at: artifacts/prepare_base_model]\n",
      "Model Configuration:\n",
      "Input Shape: (224, 224, 3)\n",
      "Weights: imagenet\n",
      "Include Top: False\n",
      "Classes: 2\n",
      "Error in get_base_model: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=imagenet\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=imagenet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     prepare_base_model\u001b[38;5;241m.\u001b[39mupdate_base_model()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     prepare_base_model_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_prepare_base_model_config()\n\u001b[1;32m      4\u001b[0m     prepare_base_model \u001b[38;5;241m=\u001b[39m PrepareBaseModel(config\u001b[38;5;241m=\u001b[39mprepare_base_model_config)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mprepare_base_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     prepare_base_model\u001b[38;5;241m.\u001b[39mupdate_base_model()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mPrepareBaseModel.get_base_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mparams_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Adjust VGG16 initialization\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVGG16\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_include_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_include_top\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbase_model_path, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/cancer/lib/python3.8/site-packages/keras/applications/vgg16.py:122\u001b[0m, in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Instantiates the VGG16 model.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mReference:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m  A `keras.Model` instance.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (weights \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m} \u001b[38;5;129;01mor\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(weights)):\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `weights` argument should be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`None` (random initialization), `imagenet` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(pre-training on ImageNet), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor the path to the weights file to be loaded.  Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m     )\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m include_top \u001b[38;5;129;01mand\u001b[39;00m classes \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf using `weights` as `\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` with `include_top` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas true, `classes` should be 1000.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived `classes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=imagenet"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n",
    "    prepare_base_model.get_base_model()\n",
    "    prepare_base_model.update_base_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea57747-5a85-44a4-a8d3-12d4148eeda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1bf96-b172-4b3d-81b0-79b66d9a0f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
